"""
Migration P0: Ajout du champ pipeline au mod√®le CurriculumChapter

Ce script migre tous les chapitres existants pour ajouter le champ pipeline:
- Tous les chapitres ‚Üí pipeline = "SPEC" (par d√©faut)
- TESTS_DYN ‚Üí pipeline = "TEMPLATE"
- D√©tection automatique: si chapitre a exercices dynamiques en DB ‚Üí "TEMPLATE"

Script idempotent: peut √™tre relanc√© sans erreur.
"""

import asyncio
import sys
import os

# Ajouter le chemin du backend au PYTHONPATH
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from motor.motor_asyncio import AsyncIOMotorClient
from backend.logger import get_logger

logger = get_logger()

# Configuration MongoDB
MONGO_URI = os.getenv("MONGO_URI", "mongodb://mongo:27017")
DB_NAME = os.getenv("DB_NAME", "lemaitremot")


async def migrate_pipeline_field():
    """
    Migration one-shot: ajoute le champ pipeline √† tous les chapitres.
    """
    client = AsyncIOMotorClient(MONGO_URI)
    db = client[DB_NAME]
    chapters_collection = db.curriculum_chapters
    exercises_collection = db.exercises
    
    logger.info("üöÄ D√©but migration: ajout champ pipeline")
    
    # R√©cup√©rer tous les chapitres
    chapters = await chapters_collection.find({}).to_list(1000)
    logger.info(f"üìö {len(chapters)} chapitres trouv√©s")
    
    updated_count = 0
    skipped_count = 0
    
    for chapter in chapters:
        code_officiel = chapter.get("code_officiel")
        
        # V√©rifier si le champ pipeline existe d√©j√†
        if "pipeline" in chapter and chapter["pipeline"]:
            logger.debug(f"‚è≠Ô∏è  Chapitre {code_officiel} a d√©j√† un pipeline: {chapter['pipeline']}")
            skipped_count += 1
            continue
        
        # D√©terminer le pipeline
        pipeline_value = "SPEC"  # Par d√©faut
        
        # TESTS_DYN ‚Üí TEMPLATE
        if code_officiel and code_officiel.upper() in ["6E_TESTS_DYN", "TESTS_DYN"]:
            pipeline_value = "TEMPLATE"
            logger.info(f"‚úÖ Chapitre {code_officiel} ‚Üí pipeline=TEMPLATE (TESTS_DYN)")
        else:
            # D√©tection automatique: v√©rifier si exercices dynamiques en DB
            chapter_code_upper = code_officiel.upper().replace("-", "_") if code_officiel else None
            if chapter_code_upper:
                try:
                    # V√©rifier si exercices dynamiques existent
                    dynamic_exercises_count = await exercises_collection.count_documents({
                        "chapter_code": chapter_code_upper,
                        "is_dynamic": True
                    })
                    
                    if dynamic_exercises_count > 0:
                        pipeline_value = "TEMPLATE"
                        logger.info(
                            f"‚úÖ Chapitre {code_officiel} ‚Üí pipeline=TEMPLATE "
                            f"(d√©tection automatique: {dynamic_exercises_count} exercices dynamiques)"
                        )
                    else:
                        logger.debug(f"üìù Chapitre {code_officiel} ‚Üí pipeline=SPEC (par d√©faut)")
                except Exception as e:
                    logger.warning(
                        f"‚ö†Ô∏è  Erreur d√©tection automatique pour {code_officiel}: {e}. "
                        f"Utilisation de SPEC par d√©faut."
                    )
        
        # Mettre √† jour le chapitre
        result = await chapters_collection.update_one(
            {"code_officiel": code_officiel},
            {"$set": {"pipeline": pipeline_value}}
        )
        
        if result.modified_count > 0:
            updated_count += 1
            logger.info(f"‚úÖ Chapitre {code_officiel} mis √† jour: pipeline={pipeline_value}")
        else:
            logger.warning(f"‚ö†Ô∏è  Aucune modification pour {code_officiel}")
    
    # Synchroniser avec le fichier JSON (si n√©cessaire)
    # Note: Le service curriculum_persistence_service fait √ßa automatiquement,
    # mais on peut forcer une sync ici si besoin
    
    logger.info(f"‚úÖ Migration termin√©e: {updated_count} chapitres mis √† jour, {skipped_count} ignor√©s")
    
    client.close()
    return updated_count, skipped_count


if __name__ == "__main__":
    asyncio.run(migrate_pipeline_field())


